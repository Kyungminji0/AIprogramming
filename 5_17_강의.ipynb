{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "pytorch: state_dict()\n",
        "현재 모델을 \"모델상태를 저장한 state_dict\"를 이용하여 상태를 설정\n",
        "torch.nn.Module 객체의 state_dict() 메서드는\n",
        "\n",
        "모델의 학습 가능한 매개변수(가중치와 바이어스)의 상태와\n",
        "버퍼(예: BatchNorm의 running mean과 variance 등)의 상태를 저장하는\n",
        "collections.OrderedDict 객체를 반환"
      ],
      "metadata": {
        "id": "7NXQneUn8DJ0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "주요 특징\n",
        "OrderedDict 형태:\n",
        "state_dict()는\n",
        "attribute 이름을 키로 하고,\n",
        "그에 대응하는 torch.Tensor를 값으로 갖는\n",
        "collections.OrderedDict 객체를 반환.\n",
        "키로 인덱싱하여 계속 보존, 돌려줌\n",
        "\n",
        "api..?"
      ],
      "metadata": {
        "id": "Wvu7NPSV-WgY"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nVOvyDKs6_7Y"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn #얼라이어스함\n",
        "from collections import OrderedDict"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 간단한 모델 정의\n",
        "class MyModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(MyModel, self).__init__()# 모듈 상속시 초기화, 반드시 필요함\n",
        "        self.linear = nn.Linear(10, 5)\n",
        "        self.bn = nn.BatchNorm1d(5) # 버퍼\n",
        "        # self.sub = nn.Sequential(\n",
        "        #     OrderedDict({\n",
        "        #         'ds00_layer': nn.Linear(5,5),\n",
        "        #         'ds00_bn':nn.BatchNorm1d(5),\n",
        "        #         'ds00_act': nn.ReLU(),\n",
        "        #         'ds01_layer': nn.Linear(5,5),\n",
        "        #     })\n",
        "        # )\n",
        "\n",
        "    def forward(self, x): #self -인스턴스 메소드일때 사용,\n",
        "    # forward는 직접 호출하면 절대 안됨\n",
        "        x = self.linear(x)\n",
        "        x = self.bn(x)\n",
        "        return x\n",
        "        #collable object 검색해보기"
      ],
      "metadata": {
        "id": "ME_y0lEQ__sx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델 인스턴스 생성\n",
        "model = MyModel()\n",
        "# 모델의 인스턴스 메소드 호출- state_dict가져옴\n",
        "state_dict = model.state_dict()\n",
        "\n",
        "for key, value in state_dict.items():\n",
        "  print(f\"{key}: {value.shape}\") #shape을 맞춰야 하기 때문에 출\n",
        "  # state_dict 내용 출력\n",
        "#for key, value in state_dict.items():\n",
        "    #print(f\"{key:<25}: {str(type(value)):<20}: {value.shape}\")#25글자, 오른쪽으로 정"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wvM_ip1bAymw",
        "outputId": "ab14125a-6048-43f2-cde0-4b929d919d11"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "linear.weight: torch.Size([5, 10])\n",
            "linear.bias: torch.Size([5])\n",
            "bn.weight: torch.Size([5])\n",
            "bn.bias: torch.Size([5])\n",
            "bn.running_mean: torch.Size([5])\n",
            "bn.running_var: torch.Size([5])\n",
            "bn.num_batches_tracked: torch.Size([])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.state_dict? #도움말 실"
      ],
      "metadata": {
        "id": "sdxESVz4ENuL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# state_dict 내용 출력\n",
        "state_dict0 = model.state_dict(prefix='ds', keep_vars=True) #버터인지 파라미터인지 볼 수 있도록 나타냄\n",
        "# state_dict 내용 출력\n",
        "for key, value in state_dict0.items():\n",
        "  print(f\"{key:<25}: {str(type(value)):<20}: {value.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z_lL8GXmEv-8",
        "outputId": "2782739b-9ba2-4304-983f-3bfb761a59fb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dslinear.weight          : <class 'torch.nn.parameter.Parameter'>: torch.Size([5, 10])\n",
            "dslinear.bias            : <class 'torch.nn.parameter.Parameter'>: torch.Size([5])\n",
            "dsbn.weight              : <class 'torch.nn.parameter.Parameter'>: torch.Size([5])\n",
            "dsbn.bias                : <class 'torch.nn.parameter.Parameter'>: torch.Size([5])\n",
            "dsbn.running_mean        : <class 'torch.Tensor'>: torch.Size([5])\n",
            "dsbn.running_var         : <class 'torch.Tensor'>: torch.Size([5])\n",
            "dsbn.num_batches_tracked : <class 'torch.Tensor'>: torch.Size([])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "keep_vars 는 기본값이 False로 buffers와 parameters 의 값만을 추출할지를 결정\n",
        "keep_vars=True 인 경우, 값 대신 tensor객체로 데이터 버퍼를 가지고 있는 dictionary가 반환됨.\n",
        "value 가 파라메터인 경우엔 Parameter 로 얻어지고,\n",
        "value 가 버퍼인 경우엔 Tensor 로 얻어짐.\n",
        "keep_vars=True 인 경우, 메모리 사용량이 커지고, 매우 느리고 복잡한 동작이 이루어지지만. 다음의 장점을 가짐.\n",
        "모델 디버깅: 모델 상태를 조사하고 특정 매개 변수나 버퍼의 값을 변경해야 하는 경우 유용\n",
        "모델 커스터마이징: 모델을 불러온 후 특정 매개 변수나 버퍼의 값을 변경해야 하는 경우 유용\n",
        "모델 저장 및 불러오기 확장: 모델 저장 및 불러오기 프로세스를 확장하고 추가적인 정보를 저장해야 하는 경우 유용\n",
        "하지만, PyTorch의 버전이 정확히 맞아야만 동작할 수 있는 등의 제한점을 가짐.\n",
        "저장의 용도로는 keep_vars=False를 사용하는 게 좋음."
      ],
      "metadata": {
        "id": "dF0a_HPJF3dT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#활용방법"
      ],
      "metadata": {
        "id": "ByOVMOGWGBiw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#pickle 직렬화시켜 저장 가능\n",
        "torch.save(model.state_dict(), 'model_state.pth')#state_dict를 파일에 저장\n",
        "\n",
        "model = MyModel()#모델 로드\n",
        "model.load_state_dict(torch.load('model_state.pth'))#저장된 state_dict를 로드하여 모델 복원\n",
        "model.eval()#평가모드로 전환 (선택사항-훈련시는 필요 x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fa_mr92fFzKH",
        "outputId": "1ae00309-d32a-4d1c-a527-e0296a8a0475"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MyModel(\n",
              "  (linear): Linear(in_features=10, out_features=5, bias=True)\n",
              "  (bn): BatchNorm1d(5, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#파라미터 업데이트\n",
        "state_dict['linear.weight'] = torch.ones_like(state_dict['linear.weight']) #shape맞추기 위해 ones_like사용\n",
        "model.load_state_dict(state_dict)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZOjF_7W0HUkL",
        "outputId": "3bcefa89-4d34-4842-9767-d3f36f4e1afc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Module의 상태 확인하기.\n",
        ".parameters(recurse=True)\n",
        "optimizer에게 학습을 통해 갱신되어야하는 model의 parameters를 넘겨줄 때 사용됨.\n",
        "\n",
        "각, 정보를 볼 때는 .named_parameter()를 이용하면, 이름을 같이 확인할 수 있음.\n",
        "\n",
        ".named_buffers()\n",
        "buffers는 역시 tensor 객체이나,\n",
        "학습과정에서 갱신이 필요한 parameters와 달리\n",
        "학습과정에서 변하지 않는 데이터를 저장하는데 사용된다.\n",
        "\n",
        "\n",
        "\n",
        ".named_buffers()는 모델 내에 정의된 모든 버퍼를 이름과 함께 dictionary 형식으로 반환함."
      ],
      "metadata": {
        "id": "KamNCYgtH7ba"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Torch: Save and Load Model\n"
      ],
      "metadata": {
        "id": "E8RUmfpKIdGT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "model전체 저장방법: torch.save"
      ],
      "metadata": {
        "id": "OIn69PqwIhiG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "모델 저장 방법\n",
        "모델의 Parameters (= weights and bias)를 저장 (Structure 등은 저장되지 않음).\n",
        "\n",
        "//\n",
        "모델의 구조를 정의하고 있는 class 의 instance 코드 상에서 생성하고,\n",
        "이 instance로 로딩을 수행해줘야 하지만,\n",
        "해당 class의 소스를 정확히 가지고 있을 경우 PyTorch 버전 등에 상관없이\n",
        "이전과 동일한 모델을 load를 통해 얻을 수 있음."
      ],
      "metadata": {
        "id": "9nC7cVX9I5BA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "load_state_dict( state_dict ) 메서드\n",
        "\n",
        "\n",
        "현재 Module 인스턴스의 상태를 argument로 넘겨진 OrderedDict 객체 state_dict를 이용 하여 설정함.\n",
        "\n",
        "\n",
        "이 메서드의 반환값은\n",
        "\n",
        "torch.nn.modules.module._IncompatibleKeys\n",
        "Module 인스턴스에 state_dict를 로드할 때 호환되지 않는 키들의 정보 가짐\n",
        "\n",
        " 2개의 attributes가짐\n",
        "  -모델의 Parameters를 복원하는데 발생한 문제를 해결하기 위한 조치를 취할 수 있음.\n",
        "\n",
        "missing_keys : 로드하려는 state_dict에는 있으나 load_state_dict메서드를 호출한 Module 객체에는 없는 키들.\n",
        "\n",
        "unexpected_keys : Module 객체에는 있으나 인자로 넘겨진 state_dict에는 없는 키들.\n"
      ],
      "metadata": {
        "id": "faan_TlTJdrA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#model 전체를 저장하고 로드 방법\n",
        "\n",
        "state_dict를 이용"
      ],
      "metadata": {
        "id": "h8AVvbNyPTdq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 필요한 library와 모듈 import\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.nn import init ##새로 추가됨\n",
        "from collections import OrderedDict\n",
        "\n",
        "# 간단한 linear regression model 정의.\n",
        "# SimpleModel0와 SimpleModel1은\n",
        "# 똑같은 구조이나 파라메터들의 초기값만 다름.\n",
        "class SimpleModel0(nn.Module):\n",
        "\n",
        "  def __init__(self, n_in_f, n_out_f):\n",
        "\n",
        "    super().__init__()\n",
        "\n",
        "\n",
        "    init_weigths = torch.ones( (n_in_f, n_out_f) )\n",
        "    init_bias = torch.zeros( (n_out_f,) )#위 두개는 빠져도 됨\n",
        "\n",
        "    self.l0 = nn.Linear(n_in_f, n_out_f)\n",
        "\n",
        "    const_weight = 1.\n",
        "    const_bias = 0.5\n",
        "\n",
        "    init.constant_(self.l0.weight, const_weight)#init:텐서 초기화\n",
        "    #inint_constant:inplace로 처리\n",
        "    if self.l0.bias is not None: # bias가 있는지 확인\n",
        "      init.constant_(self.l0.bias, const_bias)\n",
        "\n",
        "  def forward(self, x):\n",
        "    return self.l0(x)\n",
        "\n",
        "class SimpleModel1(nn.Module):\n",
        "\n",
        "  def __init__(self, n_in_f, n_out_f):\n",
        "\n",
        "    super().__init__()\n",
        "\n",
        "    init_weigths = torch.ones( (n_in_f, n_out_f) )\n",
        "    init_bias = torch.zeros( (n_out_f,) )\n",
        "\n",
        "    self.l0 = nn.Linear(n_in_f, n_out_f)\n",
        "\n",
        "    const_weight = 2.\n",
        "    const_bias = 1.5\n",
        "\n",
        "    init.constant_(self.l0.weight, const_weight)\n",
        "    if self.l0.bias is not None:\n",
        "      init.constant_(self.l0.bias, const_bias)\n",
        "\n",
        "  def forward(self, x):\n",
        "    return self.l0(x)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "RHOUQYpPKzMd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델 객체를 생성하고, 이에 대한 파라메터 확인후\n",
        "# 파라메터만 저장.\n",
        "model = SimpleModel0(3,1)\n",
        "print(list(model.named_parameters()))\n",
        "torch.save(model.state_dict(), 'model_params.pth')\n",
        "\n",
        "# 새로운 모델 객체를 생성.\n",
        "# 해당 모델 객체는 구조는 같으나, 파라메터들의 초기값은 다름.\n",
        "n_model = SimpleModel1(3,1)\n",
        "\n",
        "print('===============')\n",
        "for old, new in zip(model.parameters(), n_model.parameters()): #zip:묶어줌\n",
        "\n",
        "  if not torch.equal(old,new):######밑에서 얘기함\n",
        "    print('model and n_model w/ default init do not have parameters with the same values!')\n",
        "    break\n",
        "else:\n",
        "  print('model and n_model w/ default init have parameters with the same values!')\n",
        "print('===============') #전부다 같은 값 가짐을 확인\n",
        "\n",
        "# 이전 저장한 parameters에 대한 state_dict를\n",
        "# 로드하고 해당 state_dict로 새로만든 모델의\n",
        "# 파라메터를 설정하고 이전 모델과 비교.\n",
        "# load parameters and restore old parameters into new model\n",
        "loaded_params_ordered_dict = torch.load('model_params.pth')\n",
        "print(f'{type(loaded_params_ordered_dict)=}') # collections.OredredDict\n",
        "\n",
        "ret_v = n_model.load_state_dict(loaded_params_ordered_dict)\n",
        "print(f'{type(ret_v)}: {ret_v}')\n",
        "\n",
        "print('===============')\n",
        "for old, new in zip(model.parameters(), n_model.parameters()):\n",
        "\n",
        "  if not torch.equal(old,new):\n",
        "    print('model and n_model do not have parameters with the same values!')\n",
        "    break\n",
        "else:\n",
        "  print('model and n_model have parameters with the same values!')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u4WbxXUfM9lP",
        "outputId": "87c488be-a63c-471e-aaf2-25548560f49b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('l0.weight', Parameter containing:\n",
            "tensor([[1., 1., 1.]], requires_grad=True)), ('l0.bias', Parameter containing:\n",
            "tensor([0.5000], requires_grad=True))]\n",
            "===============\n",
            "model and n_model w/ default init do not have parameters with the same values!\n",
            "===============\n",
            "type(loaded_params_ordered_dict)=<class 'collections.OrderedDict'>\n",
            "<class 'torch.nn.modules.module._IncompatibleKeys'>: <All keys matched successfully>\n",
            "===============\n",
            "model and n_model have parameters with the same values!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# load parameters and restore old parameters into new model\n",
        "loaded_params_ordered_dict = torch.load('model_params.pth')\n",
        "\n",
        "incompatible_keys = n_model.load_state_dict(loaded_params_ordered_dict)\n",
        "print(f'{type(incompatible_keys)}: {incompatible_keys}')\n",
        "print(f'{incompatible_keys.missing_keys=}')\n",
        "print(f'{incompatible_keys.unexpected_keys=}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7VgO3vorNLKg",
        "outputId": "d7d91cdd-6940-4be2-cceb-1e26286445d4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'torch.nn.modules.module._IncompatibleKeys'>: <All keys matched successfully>\n",
            "incompatible_keys.missing_keys=[]\n",
            "incompatible_keys.unexpected_keys=[]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for old, new in zip(model.parameters(), n_model.parameters()): #old에는 첫번쨰 파라미터, new새로운 파라미\n",
        "\n",
        "  if not torch.equal(old,new):\n",
        "    print('model and n_model do not have parameters with the same values!')\n",
        "    break\n",
        "else:\n",
        "  print('model and n_model have parameters with the same values!')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "99nEc2NxNNtp",
        "outputId": "76ed4c4a-bbe0-4569-9490-8dc111033fb4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "model and n_model have parameters with the same values!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#session을 초기화한 후 다시 수행\n",
        "\n",
        "class definitiond이 session 초기화로 없어지므로 에러 발생."
      ],
      "metadata": {
        "id": "94u-9q6OOEi0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torch.nn import init\n",
        "from collections import OrderedDict\n",
        "\n",
        "n_model = torch.load('model.pth')\n",
        "print(f'{type(n_model)=}, {n_model}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 370
        },
        "id": "PRBrBXxEQCod",
        "outputId": "182164a8-1a47-4c93-dea2-5a7d8cd7af2d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'model.pth'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-dfe03e3f8130>\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mcollections\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mOrderedDict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mn_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'model.pth'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'{type(n_model)=}, {n_model}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[0m\n\u001b[1;32m    996\u001b[0m         \u001b[0mpickle_load_args\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'encoding'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    997\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 998\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mopened_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    999\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_is_zipfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1000\u001b[0m             \u001b[0;31m# The zipfile reader is going to advance the current file position.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_open_file_like\u001b[0;34m(name_or_buffer, mode)\u001b[0m\n\u001b[1;32m    443\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    444\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_is_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 445\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    446\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    447\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m'w'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode)\u001b[0m\n\u001b[1;32m    424\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_opener\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    425\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 426\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    427\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    428\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__exit__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'model.pth'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class SimpleModel0(nn.Module):\n",
        "\n",
        "  def __init__(self, n_in_f, n_out_f):\n",
        "\n",
        "    super().__init__()\n",
        "\n",
        "    init_weigths = torch.ones( (n_in_f, n_out_f) )\n",
        "    init_bias = torch.zeros( (n_out_f,) )\n",
        "\n",
        "    self.l0 = nn.Linear(n_in_f, n_out_f)\n",
        "\n",
        "    const_weight = 2.\n",
        "    const_bias = 1.5\n",
        "\n",
        "    init.constant_(self.l0.weight, const_weight)\n",
        "    if self.l0.bias is not None:\n",
        "      init.constant_(self.l0.bias, const_bias)\n",
        "\n",
        "  def forward(self, x):\n",
        "    return self.l0(x)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "fBHStHfmQJO_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_model = torch.load('model.pth')\n",
        "print(f'{type(n_model)=}, {n_model}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 351
        },
        "id": "DkiKL0FiQfMZ",
        "outputId": "66aa3872-5e94-438b-b2e7-28ecefa562e1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'model.pth'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-cdda03d0128c>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mn_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'model.pth'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'{type(n_model)=}, {n_model}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[0m\n\u001b[1;32m    996\u001b[0m         \u001b[0mpickle_load_args\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'encoding'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    997\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 998\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mopened_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    999\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_is_zipfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1000\u001b[0m             \u001b[0;31m# The zipfile reader is going to advance the current file position.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_open_file_like\u001b[0;34m(name_or_buffer, mode)\u001b[0m\n\u001b[1;32m    443\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    444\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_is_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 445\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    446\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    447\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m'w'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode)\u001b[0m\n\u001b[1;32m    424\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_opener\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    425\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 426\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    427\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    428\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__exit__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'model.pth'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "for c in n_model.named_parameters():\n",
        "  print(c)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZXVk6_9FQM-S",
        "outputId": "f75f2868-6efa-44df-90b4-baa898a1f2b6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('l0.weight', Parameter containing:\n",
            "tensor([[1., 1., 1.]], requires_grad=True))\n",
            "('l0.bias', Parameter containing:\n",
            "tensor([0.5000], requires_grad=True))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "pickle.dump(n_model, open('m', 'pkl', 'wb'))\n",
        "nn_model = model = pickle.load(open{'m,pkl','rb'})\n",
        "nn_model"
      ],
      "metadata": {
        "id": "WwWfA-bYSvtT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for old, new in zip(n_model,paraneters(), nn_model.parameters()):\n",
        "\n",
        "  if not torch.equal(old,new):\n",
        "    print('model and n_model do not have#...')"
      ],
      "metadata": {
        "id": "XLL9W8HYTjUO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#PyTorch: Tensor 비교하기\n",
        "\n",
        "이 방법은 두 텐서가 완전히 동일한지를 확인."
      ],
      "metadata": {
        "id": "8FB6_lfyU4Hl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. torch.equal 사용\n",
        "\n",
        "이 방법은 두 텐서가 완전히 동일한지를 확인."
      ],
      "metadata": {
        "id": "-dzyrnm4VaGL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "# nn.Parameter 객체 생성\n",
        "param1 = nn.Parameter(torch.tensor([1.0, 2.0, 3.0]))\n",
        "param2 = nn.Parameter(torch.tensor([1.0, 2.0, 3.0]))\n",
        "param3 = nn.Parameter(torch.tensor([1.0, 2.0, 4.0]))\n",
        "\n",
        "# 값 비교\n",
        "print(torch.equal(param1, param2))  # True\n",
        "print(torch.equal(param1, param3))  # False"
      ],
      "metadata": {
        "id": "2l3ZkqDbU2J2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. torch.allclose 사용\n",
        "\n",
        "이 방법은 두 텐서가 지정된 허용 오차 내에서 거의 동일한지를 확인.\n",
        "\n",
        "이는 부동 소수점 연산의 미세한 차이로 인한 불일치를 허용할 수 있음 (권장)."
      ],
      "metadata": {
        "id": "MzmqMSWkVbTr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "# nn.Parameter 객체 생성\n",
        "param1 = nn.Parameter(torch.tensor([1.0, 2.0, 3.0]))\n",
        "param2 = nn.Parameter(torch.tensor([1.0, 2.0, 3.0000001]))\n",
        "param3 = nn.Parameter(torch.tensor([1.0, 2.0, 4.0]))\n",
        "\n",
        "# 값 비교\n",
        "print(torch.allclose(param1, param2))  # True, 기본 허용 오차 내\n",
        "print(torch.allclose(param1, param3))  # False"
      ],
      "metadata": {
        "id": "QKnSnMMEVnsr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2-1. torch.allclose의 허용 오차 설정\n",
        "\n",
        "허용 오차를 설정하여 두 텐서가 거의 동일한지 확인할 수 있음."
      ],
      "metadata": {
        "id": "hsgqyI6eVtRJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "# nn.Parameter 객체 생성\n",
        "param1 = nn.Parameter(torch.tensor([1.0, 2.0, 3.0]))\n",
        "param2 = nn.Parameter(torch.tensor([1.0, 2.0, 3.0001]))\n",
        "\n",
        "# 값 비교, 허용 오차 설정\n",
        "print(torch.allclose(param1, param2, atol=1e-4))  # True, 허용 오차 내\n",
        "print(torch.allclose(param1, param2, atol=1e-5))  # False, 허용 오차 밖"
      ],
      "metadata": {
        "id": "ltuZmxRGVvpI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "설명\n",
        "\n",
        "\n",
        "torch.allclose(tensor1, tensor2, rtol=1e-05, atol=1e-08):\n",
        "두 텐서가 상대적(rtol) 및 절대적(atol) 허용 오차 내에서 거의 동일한지 확인."
      ],
      "metadata": {
        "id": "dGWCS1EhVxSw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# PyTorch: nn.ModuleList, nn.ModuleDict, nn.Sequential"
      ],
      "metadata": {
        "id": "zjwxQTvzV0YN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. nn.Sequential\n",
        "\n",
        "여러 모듈을 순차적으로 실행할 수 있도록 하는 PyTorch 클래스\n",
        "\n",
        "간단한 네트워크 구조를 만들 때 유용하며, 모듈을 정의한 순서대로 순차적으로 적용"
      ],
      "metadata": {
        "id": "ywXZ9byfWrXw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "model = nn.Sequential(\n",
        "    nn.Linear(10, 20),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(20, 10)\n",
        ")\n",
        "\n",
        "print(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lss9LpPhWop0",
        "outputId": "e33b1ff9-5b46-46b9-c2a1-78f83473e85c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sequential(\n",
            "  (0): Linear(in_features=10, out_features=20, bias=True)\n",
            "  (1): ReLU()\n",
            "  (2): Linear(in_features=20, out_features=10, bias=True)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "=>nn.Sequential은 nn.Linear와 nn.ReLU 모듈을 순차적으로 포함하고 있으며, 정의한 순서대로 순차적으로 적용함.\n",
        "\n",
        "nn.Sequential을 사용하면 네트워크 구조를 직관적으로 정의"
      ],
      "metadata": {
        "id": "kFxipudiW7tB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. nn.ModuleList\n",
        "\n",
        "PyTorch의 nn.Module을 리스트처럼 다루기 위한 클래스\n",
        "리스트에 포함된 모든 모듈이 PyTorch의 모델 구성 요소로 인식되어 올바르게 등록되고 관리됨.\n",
        "\n",
        "이는 모델 파라미터가 자동으로 추적되며, to(), cuda(), cpu()와 같은 메서드를 사용할 수 있게 함."
      ],
      "metadata": {
        "id": "06Hvq8SBW9ic"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class MyModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(MyModel, self).__init__()\n",
        "        self.layers = nn.ModuleList([ #꼭 묶어 주어야 함\n",
        "            nn.Linear(10, 20),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(20, 10)\n",
        "        ])\n",
        "\n",
        "    def forward(self, x):\n",
        "        for layer in self.layers:\n",
        "            x = layer(x)\n",
        "        return x\n",
        "\n",
        "model = MyModel()\n",
        "print(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZlkbNdRlXI9B",
        "outputId": "292605ec-d51a-4d5b-c4e3-3719372aa048"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MyModel(\n",
            "  (layers): ModuleList(\n",
            "    (0): Linear(in_features=10, out_features=20, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Linear(in_features=20, out_features=10, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "=>리스트 안에 nn.Linear와 nn.ReLU 모듈을 포함\n",
        "\n",
        "forward 메서드에서는 리스트에 포함된 각 모듈을 순차적으로 적용"
      ],
      "metadata": {
        "id": "VxGTrXztXOm_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. nn.ModuleDict (이걸 권함)\n",
        "\n",
        "PyTorch의 nn.Module을 딕셔너리처럼 다루기 위한 클래스\n",
        "딕셔너리에 포함된 모든 모듈이 PyTorch의 모델 구성 요소로 인식되어 올바르게 등록되고 관리됨.\n",
        "\n",
        "이는 모델 파라미터가 자동으로 추적되며, to(), cuda(), cpu()와 같은 메서드를 사용할 수 있게 함."
      ],
      "metadata": {
        "id": "FbojQl3QXhHq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class MyModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(MyModel, self).__init__()\n",
        "        self.layers = nn.ModuleDict({\n",
        "            'fc1': nn.Linear(10, 20),\n",
        "            'relu': nn.ReLU(),\n",
        "            'fc2': nn.Linear(20, 10)\n",
        "        })\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.layers['fc1'](x)\n",
        "        x = self.layers['relu'](x)\n",
        "        x = self.layers['fc2'](x)\n",
        "        return x\n",
        "\n",
        "model = MyModel()\n",
        "print(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w4wpLIDOXq47",
        "outputId": "44683b52-a279-4e4d-f109-b12aa2a91c57"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MyModel(\n",
            "  (layers): ModuleDict(\n",
            "    (fc1): Linear(in_features=10, out_features=20, bias=True)\n",
            "    (relu): ReLU()\n",
            "    (fc2): Linear(in_features=20, out_features=10, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "=> 키-값 쌍으로 nn.Linear와 nn.ReLU 모듈을 포함하고 있음.\n",
        "\n",
        "forward 메서드에서는 딕셔너리의 키를 사용하여 각 모듈을 순차적으로 적용함.\n",
        "\n"
      ],
      "metadata": {
        "id": "KhF7IKQkXt6J"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 일반 list나 dict를 사용할 때 발생하는 문제"
      ],
      "metadata": {
        "id": "tIEDwJfLXzaD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "일반 list나 dict를\n",
        "\n",
        "nn.ModuleList나 nn.ModuleDict 대신 사용하면 여러 가지 문제가 발생\n",
        "\n",
        "**문제점은 list 또는 dict 내의 모듈들의\n",
        "파라메터 자동 추적 이 이루어지지 않는 다는 점임."
      ],
      "metadata": {
        "id": "QnmxvQwAX2ss"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "PyTorch는\n",
        "\n",
        "nn.ModuleList나 nn.ModuleDict에 포함된 모듈의 파라미터를 자동으로 추적함.\n",
        "\n",
        "이를 통해 모델의 모든 파라미터가 자동으로 등록되고, parameters() 메서드을 통해 optim 등에서 쉽게 접근"
      ],
      "metadata": {
        "id": "oMbz_QxtYA6z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "##문제점 확인 코드\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class MyModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(MyModel, self).__init__()\n",
        "        self.layers = [\n",
        "            nn.Linear(10, 20),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(20, 10)\n",
        "        ]\n",
        "\n",
        "    def forward(self, x):\n",
        "        for layer in self.layers:\n",
        "            x = layer(x)\n",
        "        return x\n",
        "\n",
        "model = MyModel()\n",
        "print(model)\n",
        "print(\"Model parameters:\", list(model.parameters()))  # 파라미터가 추적되지 않음\n",
        "#텅 빈 형태로 출"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tCUwXzxSZarJ",
        "outputId": "359aa68a-71a3-40c7-803d-1c8e1ad75e53"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MyModel()\n",
            "Model parameters: []\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**이는 GPU/CPU 이동할 때에도 문제가 됨\n",
        "\n",
        "nn.ModuleList나 nn.ModuleDict를 사용하면,\n",
        "\n",
        "model.to('cuda')나 model.cuda()와 같은 메서드를 호출할 때 포함된 모든 모듈이 자동으로 GPU로 이동하지만,\n",
        "\n",
        "list나 dict를 사용하면 이 동작이 자동으로 이루어지지 않음.\n"
      ],
      "metadata": {
        "id": "1H8dlGUyYIpB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#문제점 확인 코\n",
        "class MyModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(MyModel, self).__init__()\n",
        "        self.layers = [\n",
        "            nn.Linear(10, 20),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(20, 10)\n",
        "        ]\n",
        "\n",
        "    def forward(self, x):\n",
        "        for layer in self.layers:\n",
        "            x = layer(x)\n",
        "        return x\n",
        "\n",
        "model = MyModel()\n",
        "model_gpu = model.to('cuda')  # 일반 list를 사용하면 GPU로 이동하지 않음"
      ],
      "metadata": {
        "id": "tzWSn8vEZnWD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "PyTorch 모델을 구성할 때는 일반 list나 dict가 아닌 nn.ModuleList, nn.ModuleDict, nn.Sequential를 사용해야 한다.\n",
        "\n",
        "달리 애기하면 top-level attribute 로 sub-module을 추가하는 경우 외에는 nn.ModuleList, nn.ModuleDict, nn.Sequential를 사용해야 한다."
      ],
      "metadata": {
        "id": "avhqJXttYP5X"
      }
    }
  ]
}